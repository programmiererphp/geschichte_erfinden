<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Interactive Story App</title>
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Roboto:wght@400;700&display=swap" rel="stylesheet">

  <style>
    *, *::before, *::after { box-sizing: border-box; }
    :root {
      --primary-color: #4361ee;
      --primary-dark: #3a56d4;
      --secondary-color: #00b4d8;
      --accent-color: #ff9f1c;
      --danger-color: #e63946;
      --success-color: #2ecc71;
      --warning-color: #ff9f1c;
      --light-bg: #f8f9fa;
      --dark-text: #2b2d42;
      --medium-text: #555b6e;
      --light-text: #8d99ae;
      --border-color: #dbe2ef;
      --card-shadow: 0 8px 20px rgba(0, 0, 0, 0.08);
      --hover-shadow: 0 12px 25px rgba(0, 0, 0, 0.12);
      --transition-speed: 0.2s;
    }
    body { 
      font-family: 'Roboto', Arial, sans-serif; 
      margin: 0; 
      padding: 20px; 
      background-color: #ebf1fa; 
      color: var(--dark-text); 
      line-height: 1.6; 
    }
    .container { 
      max-width: 850px; 
      margin: 20px auto; 
      background: #ffffff; 
      padding: 30px 35px; 
      border-radius: 16px; 
      box-shadow: var(--card-shadow); 
      position: relative;
      overflow: hidden;
    }
    .container::before {
      content: '';
      position: absolute;
      top: 0;
      left: 0;
      width: 100%;
      height: 5px;
      background: linear-gradient(to right, var(--primary-color), var(--secondary-color));
    }
    h1, h2, h3 { 
      text-align: center; 
      color: var(--dark-text); 
      margin-top: 0; 
      margin-bottom: 15px; 
    }
    h1 { 
      font-size: 2.2em; 
      margin-bottom: 25px; 
      background: linear-gradient(to right, var(--primary-color), var(--secondary-color));
      -webkit-background-clip: text;
      -webkit-text-fill-color: transparent;
      background-clip: text;
      text-fill-color: transparent;
    }
    h2 { 
      font-size: 1.4em; 
      border-bottom: 2px solid var(--border-color); 
      padding-bottom: 10px; 
      margin-bottom: 15px; 
    }
    h3 { 
      font-size: 1.2em; 
      color: var(--medium-text); 
    }
    button { 
      padding: 10px 18px; 
      margin: 6px; 
      font-size: 0.95em; 
      cursor: pointer; 
      border: none; 
      border-radius: 8px; 
      background-color: var(--primary-color); 
      color: white; 
      transition: all var(--transition-speed) ease; 
      font-weight: bold; 
      box-shadow: 0 3px 6px rgba(0,0,0,0.1);
    }
    button:hover:not(:disabled) { 
      background-color: var(--primary-dark); 
      transform: translateY(-2px); 
      box-shadow: var(--hover-shadow); 
    }
    button:active:not(:disabled) { 
      transform: translateY(0px); 
    }
    button:disabled { 
      background-color: var(--light-text); 
      cursor: not-allowed; 
      opacity: 0.7; 
      box-shadow: none;
    }
    button.active {
      animation: pulse 1.5s infinite;
      box-shadow: 0 0 0 0 rgba(67, 97, 238, 0.7);
    }
    @keyframes pulse {
      0% {
        box-shadow: 0 0 0 0 rgba(67, 97, 238, 0.7);
      }
      70% {
        box-shadow: 0 0 0 10px rgba(67, 97, 238, 0);
      }
      100% {
        box-shadow: 0 0 0 0 rgba(67, 97, 238, 0);
      }
    }
    .section { 
      border: 1px solid var(--border-color); 
      padding: 18px; 
      background: var(--light-bg); 
      margin: 18px 0; 
      border-radius: 12px; 
      min-height: 40px; 
      box-shadow: 0 2px 8px rgba(0,0,0,0.04);
      transition: all var(--transition-speed) ease;
    }
    .section:hover {
      box-shadow: 0 4px 12px rgba(0,0,0,0.08);
    }
    .section h2 {
      display: flex;
      align-items: center;
      justify-content: center;
      margin-top: 0;
    }
    .section h2::before, .section h2::after {
      content: '';
      height: 1px;
      background-color: var(--border-color);
      flex: 1;
      margin: 0 15px;
    }
    #controlsContainer { 
      display: flex; 
      justify-content: center; 
      align-items: center; 
      flex-wrap: wrap; 
      margin-bottom: 25px; 
      padding: 15px;
      background-color: rgba(219, 226, 239, 0.2);
      border-radius: 12px;
    }
    #stopTTSBtn { 
      background-color: var(--danger-color); 
      margin-left: 15px; 
    }
    #stopTTSBtn:hover:not(:disabled) { 
      background-color: #d63031; 
    }
    #stopTTSBtn:disabled { 
      background-color: #fab1a0; 
      opacity: 0.6; 
    }
    #startGameBtn {
      background-color: var(--success-color);
    }
    #startGameBtn:hover:not(:disabled) {
      background-color: #27ae60;
    }
    #restartGameBtn {
      background-color: var(--warning-color);
    }
    #restartGameBtn:hover:not(:disabled) {
      background-color: #f39c12;
    }
    #stopGameBtn {
      background-color: var(--danger-color);
    }
    #stopGameBtn:hover:not(:disabled) {
      background-color: #d63031;
    }
    #recordButtons { 
      text-align: center; 
      margin-top: 20px; 
      padding-top: 18px; 
      border-top: 1px dashed #bdc3c7; 
    }
    #recordButtons button { 
      font-size: 1.1em; 
      padding: 12px 25px; 
      margin: 0 10px; 
      display: inline-flex;
      align-items: center;
      justify-content: center;
    }
    #startRecordBtn { 
      background-color: var(--success-color); 
    }
    #startRecordBtn::before {
      content: 'üé§ ';
      margin-right: 5px;
    }
    #startRecordBtn:hover:not(:disabled) { 
      background-color: #27ae60; 
    }
    #stopRecordBtn { 
      background-color: var(--warning-color); 
    }
    #stopRecordBtn::before {
      content: '‚èπÔ∏è ';
      margin-right: 5px;
    }
    #stopRecordBtn:hover:not(:disabled) { 
      background-color: #e67e22; 
    }
    #recordCountdown { 
      font-weight: bold; 
      text-align: center; 
      margin: 15px 0 10px 0; 
      color: var(--danger-color); 
      font-size: 1.1em;
    }
    #loadingIndicator { 
      display: none; 
      text-align: center; 
      padding: 15px; 
      color: var(--medium-text); 
      font-weight: bold; 
      background-color: #eef2fd; 
      border-radius: 10px; 
      margin: 15px 0; 
      box-shadow: 0 2px 6px rgba(0,0,0,0.05);
      animation: fadeInOut 1.5s infinite alternate;
    }
    @keyframes fadeInOut {
      from { opacity: 0.7; }
      to { opacity: 1; }
    }
    #apiCountdown { 
      font-weight: normal; 
      margin-left: 10px; 
      color: var(--primary-color); 
    }
    .debugDetail { 
      font-size: 0.85em; 
      color: var(--medium-text); 
      margin-top: 10px; 
      border-top: 1px dashed var(--border-color); 
      padding-top: 12px; 
      white-space: pre-wrap; 
      word-wrap: break-word; 
      background-color: #f8fafd; 
      padding: 12px; 
      border-radius: 8px; 
    }
    .modal { 
      display: none; 
      position: fixed; 
      z-index: 10; 
      left: 0; 
      top: 0; 
      width: 100%; 
      height: 100%; 
      overflow: auto; 
      background-color: rgba(0,0,0,0.5); 
      backdrop-filter: blur(3px);
    }
    .modal-content { 
      background-color: #fff; 
      margin: 5% auto; 
      padding: 30px 35px; 
      border: none; 
      width: 90%; 
      max-width: 800px; 
      border-radius: 16px; 
      box-shadow: var(--card-shadow); 
      position: relative;
      animation: modalopen 0.4s;
    }
    @keyframes modalopen {
      from {opacity: 0; transform: translateY(-20px);}
      to {opacity: 1; transform: translateY(0);}
    }
    .close { 
      color: var(--light-text); 
      float: right; 
      font-size: 32px; 
      font-weight: bold; 
      cursor: pointer; 
      line-height: 1; 
      transition: color 0.2s;
    }
    .close:hover, .close:focus { 
      color: var(--dark-text); 
      text-decoration: none; 
    }
    textarea, input[type="text"], input[type="time"], select { 
      width: 100%; 
      padding: 12px; 
      margin: 8px 0 20px 0; 
      box-sizing: border-box; 
      border: 1px solid var(--border-color); 
      border-radius: 8px; 
      background-color: #fdfdfd; 
      font-family: inherit; 
      font-size: 0.95em; 
      transition: border-color 0.2s, box-shadow 0.2s;
    }
    textarea:focus, input:focus, select:focus {
      border-color: var(--primary-color);
      box-shadow: 0 0 0 3px rgba(67, 97, 238, 0.15);
      outline: none;
    }
    textarea { 
      min-height: 90px; 
    }
    label { 
      display: block; 
      margin-bottom: 6px; 
      font-weight: 600; 
      color: var(--medium-text); 
      font-size: 0.95em;
    }
    .modelInfo { 
      font-size: 0.9em; 
      color: var(--light-text); 
      margin-top: 15px; 
      text-align: center; 
      padding: 8px;
      background-color: #f8fafd;
      border-radius: 8px;
    }
    #debugLog { 
      height: 250px; 
      overflow-y: auto; 
      border: 1px solid var(--border-color); 
      background: #f8fafd; 
      padding: 12px; 
      font-family: monospace; 
      font-size: 0.9em; 
      white-space: pre-wrap; 
      word-wrap: break-word; 
      border-radius: 8px; 
    }
    .theme-instructions { 
      display: none; 
      margin-top: 15px; 
      padding: 18px; 
      border: 1px dashed var(--primary-color); 
      background-color: #eef2fd; 
      border-radius: 8px; 
    }
    .theme-instructions textarea { 
      background-color: #fff; 
      font-size: 0.85em; 
      color: var(--medium-text); 
    }
    .warning { 
      color: var(--danger-color); 
      font-size: 0.9em; 
      margin-top: -8px; 
      margin-bottom: 12px; 
      background-color: rgba(230, 57, 70, 0.08);
      padding: 8px 12px;
      border-radius: 6px;
    }
    hr {
      border: none;
      height: 1px;
      background-color: var(--border-color);
      margin: 25px 0;
    }
    #nextHint {
      position: relative;
    }
    #nextHint::after {
      content: 'üëà Speak here';
      position: absolute;
      bottom: 30px;
      right: 20px;
      background-color: rgba(67, 97, 238, 0.1);
      padding: 8px 16px;
      border-radius: 20px;
      font-size: 0.9em;
      color: var(--primary-color);
      pointer-events: none;
      opacity: 0;
      transform: translateX(10px);
      transition: all 0.3s ease;
    }
    #nextHint:hover::after {
      opacity: 1;
      transform: translateX(0);
    }
  </style>
</head>
<body>
  <div class="container">
    <div id="instructionBanner" style="background-color: #eef2fd; padding: 12px 18px; border-radius: 8px; margin-bottom: 20px; display: flex; align-items: center; border-left: 4px solid var(--primary-color);">
      <div style="margin-right: 15px; font-size: 24px;">üí°</div>
      <div>
        <strong id="howToUseTitle">How to use:</strong> <span id="instructionText">Press Start Game, then click the Start Recording button in the Hint section and speak your contribution to the story. The AI will integrate your input into the narrative.</span>
      </div>
      <button id="dismissInstructions" style="margin-left: auto; background: transparent; color: var(--medium-text); box-shadow: none; font-size: 20px;">√ó</button>
    </div>
    <h1 id="appTitle">Interactive Story App</h1>

    <div id="controlsContainer">
        <div>
            <button id="startGameBtn">‚ñ∂Ô∏è Start Game</button>
            <button id="restartGameBtn">üîÑ Restart Game</button>
            <button id="stopGameBtn">‚èπÔ∏è Stop Game</button>
            <button id="settingsBtn">‚öôÔ∏è Settings & Debug</button>
            <button id="showContribsBtn">üìã Show Contributions</button>
        </div>
        <button id="stopTTSBtn" disabled>üîá Stop Speaking</button>
    </div>

    <div id="modelInfo" class="modelInfo">
      Using models: STT: whisper-1 | TTS: Browser SpeechSynthesis
    </div>

    <div id="loadingIndicator">
      <span id="processingText">Processing request... Please wait.</span>
      <span id="apiCountdown"></span>
    </div>

    <div id="recordCountdown"></div>

    <!-- Output Sections -->
    <div id="benutzerBeitrag" class="section">
      <h2 id="lastUserInputTitle">Last User Input (Transcript)</h2>
      <div id="lastUserText">No input yet.</div>
    </div>
    <div id="ironicCommentSection" class="section">
      <h2 id="commentFeedbackTitle">Comment / Feedback</h2>
      <div id="ironicText">Waiting for the first contribution...</div>
    </div>
    <div id="currentStory" class="section">
      <h2 id="currentStoryTitle">Current Story</h2>
      <div id="storyText">No story started yet.</div>
      <div id="storyDebug" class="debugDetail" style="display:none;">No Story Debug Info.</div>
    </div>
    <div id="nextHint" class="section">
      <h2 id="hintTitle">Hint</h2>
      <div id="hintText">Start the game to get a hint.</div>
       <div id="recordButtons" style="display:none;">
         <button id="startRecordBtn">Start Recording</button>
         <button id="stopRecordBtn" disabled>Stop Recording</button>
       </div>
      <div id="hintDebug" class="debugDetail" style="display:none;">No Hint Debug Info.</div>
    </div>
  </div>

  <!-- Settings Modal -->
  <div id="settingsModal" class="modal">
    <div class="modal-content">
      <span class="close" id="settingsClose">√ó</span>
      <h2 id="settingsTitle">Settings & Debug</h2>
      <div id="openRouterNote" class="warning">Note: This app now uses Open Router for LLM API calls instead of OpenAI directly.</div>
      <div>
        <label id="apiKeyLabel" for="apiKey">Open Router API Key:</label>
        <input type="text" id="apiKey" placeholder="Enter Open Router API key here (sk-...)">
      </div>
      <div>
        <label id="modelSelectLabel" for="modelSelect">Open Router Model (Free Options):</label>
        <select id="modelSelect">
          <option value="deepseek/deepseek-chat-v3-0324:free">DeepSeek Chat v3 (FREE)</option>
          <option value="google/gemini-2.0-flash-exp:free">Gemini 2.0 Flash (FREE)</option>
        </select>
      </div>
      <div>
        <label id="interfaceLanguageLabel" for="languageSelect">Interface & TTS Language:</label>
        <select id="languageSelect">
          <option value="de">Deutsch</option>
          <option value="en">English</option>
          <option value="ru">–†—É—Å—Å–∫–∏–π</option>
        </select>
      </div>
      <hr>
      <h3 id="ttsSettingsTitle">Text-to-Speech (TTS) Settings</h3>
      <div>
        <label id="ttsProviderLabel" for="ttsProviderSelect">TTS Provider:</label>
        <select id="ttsProviderSelect">
            <option value="browser">Browser Default</option>
            <option value="elevenlabs">ElevenLabs</option>
            <option value="google">Google Cloud TTS</option>
        </select>
      </div>
      <div id="elevenlabsSettings">
          <label for="elevenLabsKey">ElevenLabs API Key:</label>
          <input type="text" id="elevenLabsKey" placeholder="ElevenLabs API Key (optional)">
          <label for="elevenLabsVoice">ElevenLabs Voice ID:</label>
          <input type="text" id="elevenLabsVoice" placeholder="Voice ID (e.g., TxGEqnHWrfWFTfGW9XjX)">
      </div>
       <div id="googleTtsSettings">
           <label for="googleApiKey">Google Cloud API Key:</label>
           <input type="text" id="googleApiKey" placeholder="Google Cloud API Key (optional)">
           <div class="warning">Note: Using Google API Key client-side is insecure for production. Restrict your key!</div>
           <label for="googleVoiceName">Google Cloud Voice Name:</label>
           <input type="text" id="googleVoiceName" placeholder="e.g., en-US-Wavenet-D, de-DE-Standard-F">
           <a href="https://cloud.google.com/text-to-speech/docs/voices" target="_blank" rel="noopener noreferrer">Find Voice Names</a> |
           <a href="https://console.cloud.google.com/apis/credentials" target="_blank" rel="noopener noreferrer">Get API Key</a>
       </div>
      <div>
        <label for="ttsStyle">TTS Style Prompt (for AI Voice Generation - affects some models):</label>
        <textarea id="ttsStyle" rows="2">
Please speak like a cheerful, enthusiastic storyteller reading a bedtime story with a warm and engaging voice.
        </textarea>
      </div>
      <hr>
       <h3 id="storyGenSettingsTitle">Story Generation Settings</h3>
      <div>
        <label id="initialPromptLabel" for="initialPrompt">Initial Prompt (Story Start):</label>
        <textarea id="initialPrompt" rows="6">
Give me a fascinating starting sentence for a story and also a short hint on how to continue the story so far (consider the previous story), returned as a question that begins with a short question about the continuation and contains exactly three answer options in parentheses (2 serious, one absurdly ironic), e.g.:
"How does it continue? (e.g.: 'He calls for caution', 'He sings a calming song', 'He dances a crazy salsa')"

Respond exclusively with a valid JSON object containing exactly the keys "startSentence" and "hint". The entire output MUST be valid JSON.
        </textarea>
      </div>
      <div>
        <label id="reactionPromptLabel" for="reactionPrompt">Reaction Prompt (Integration & Comment):</label>
        <textarea id="reactionPrompt" rows="9">
Story Request: You have this story so far: "{story}"
and the last user input: "{lastUser}".

You are a master storyteller. Rather than directly inserting the user's words, creatively transform and integrate their contribution into the narrative as follows:

1. **Story Integration:** Interpret the essence of the user's idea and develop it further. Add descriptive details, elaborate on emotions, enhance the setting, or introduce interesting consequences. Make their contribution feel like a natural progression of the story while elevating its quality.

2. **Narrative Style:** Maintain a consistent narrative voice and tone. Use varied sentence structures, vivid descriptions, and appropriate literary devices that fit the story's genre and atmosphere.

3. **Commentary:** Provide a short, dryly ironic comment about the user's contribution, with a touch of humor or insight about their creative choice.

4. **Continuation Hint:** Offer a new hint for continuing the story based on the enhanced narrative. Frame it as a question with exactly three option examples (two reasonable ones and one absurdly ironic), e.g.:
"What emotional revelation comes next? (e.g.: 'She confronts her long-hidden fear', 'He discovers an unexpected truth about his past', 'The teapot suddenly reveals its deep existential crisis')"

Respond exclusively with a valid JSON object containing exactly the keys "integratedStory", "comment", and "hint". The entire output MUST be valid JSON.
        </textarea>
      </div>
       <!-- Theme Instructions -->
       <div id="germanA2PromptSection" class="theme-instructions">
         <label>Additional Instruction for "Learn German A2":</label>
         <textarea id="germanA2Prompt" rows="12" readonly>
# Special instructions for the theme "Learn German A2":
1.  **Story Language Level (`integratedStory`, `hint`):** Keep the generated story and hint in **simple German (A2 level)**. Use short sentences, common vocabulary, and basic grammar structures (Pr√§sens, Perfekt, simple subordinate clauses).
2.  **Error Analysis:** Analyze the user input (`{lastUser}`) for typical A2 level German grammar mistakes (e.g., wrong articles, verb conjugation, sentence structure, case errors after prepositions).
3.  **Comment Language (`comment`):** Generate the comment **in {commentLang}**. The comment should be short, slightly ironic, but *helpful*, directly addressing *one* identified grammar mistake. Briefly explain the error and provide the correct form. Example (if commentLang is English): "Haha, almost! Remember, after 'mit' (with) we always use Dativ, so it's 'mit dem Freund' (with the friend - masc.), not 'mit den Freund'. But the idea of a friend in the fridge is... interesting!" If no typical A2 error is found, provide a generally encouraging comment in {commentLang}.
4.  **Hint Focus (`hint`):** The hint (in German A2) should subtly encourage practicing the grammar topic that was incorrect in the user input. E.g., if Dativ after 'mit' was wrong, the hint could be: "Was passiert als N√§chstes? (z.B.: 'Er spricht mit [wem? Dativ!]...', 'Sie geht ohne [wen? Akkusativ!]...', 'Die Katze springt auf [wohin? Akkusativ!]...')". Focus on *one* grammar topic per hint.
5.  **JSON Structure:** Strictly maintain the JSON structure `{"integratedStory": "...", "comment": "...", "hint": "..."}`.
        </textarea>
      </div>
      <div id="lifecoachPromptSection" class="theme-instructions">
         <label>Additional Instruction for "Lifecoach":</label>
         <textarea id="lifecoachPrompt" rows="12" readonly>
# Special instructions for the theme "Lifecoach (Playful & Spontaneous)":
1.  **Persona:** Adopt the persona of a *playful, spontaneous, helpful, and easy-going lifecoach* within the narrative.
2.  **Story Integration (`integratedStory`):** Weave the story forward, potentially modeling the desired traits (playfulness, spontaneity) or presenting lighthearted scenarios related to the user's input. The tone should be encouraging and light.
3.  **Comment/Feedback (`comment`):** Provide a *helpful and encouraging comment* in {commentLang}, acting as the lifecoach. Relate it to the user's input or the story's situation. Offer a simple reflection, a playful observation, or a gentle nudge towards spontaneity or ease. Example: "Great idea to just jump in! Sometimes the best plan is no plan, right? What tiny spontaneous thing could happen next?"
4.  **Hint (`hint`):** The hint should encourage playful or spontaneous next steps, or pose a simple reflective question related to ease or helpfulness. Example: "What happens now? (e.g. 'They decide to sing to the ducks', 'They take an unexpected detour just for fun', 'They offer a stranger a compliment')"
5.  **JSON Structure:** Strictly maintain the JSON structure `{"integratedStory": "...", "comment": "...", "hint": "..."}`.
        </textarea>
      </div>
      <div id="creativewritingPromptSection" class="theme-instructions">
         <label>Additional Instruction for "Creative Writing Assistant":</label>
         <textarea id="creativewritingPrompt" rows="12" readonly>
# Special instructions for the theme "Creative Writing Assistant":
1.  **Focus:** Prioritize evocative language, sensory details, and creative descriptions. The plot might advance slowly.
2.  **Story Integration (`integratedStory`):** Continue the story, focusing on expanding the description of the scene, characters' feelings, or atmosphere based on the user's input. Use metaphors, similes, or interesting vocabulary.
3.  **Comment/Feedback (`comment`):** Provide feedback in {commentLang} on the user's contribution from a writing perspective. It could praise a good description, gently suggest adding more sensory detail, or offer a related mini-writing prompt. Example: "Nice action! How could you describe the *sound* of that happening? Adding sounds can really bring a scene to life."
4.  **Hint (`hint`):** The hint should prompt the user to focus on a specific writing technique or descriptive element. Example: "How does the scene continue? (e.g. 'Describe the smell in the air', 'Focus on the main character's internal thought', 'Use a metaphor to describe the light')"
5.  **JSON Structure:** Strictly maintain the JSON structure `{"integratedStory": "...", "comment": "...", "hint": "..."}`.
        </textarea>
      </div>
      <div id="mindfulnessPromptSection" class="theme-instructions">
         <label>Additional Instruction for "Mindfulness Moment":</label>
         <textarea id="mindfulnessPrompt" rows="12" readonly>
# Special instructions for the theme "Mindfulness Moment":
1.  **Pacing:** The story should be calm and progress slowly. Focus on presence and awareness.
2.  **Story Integration (`integratedStory`):** Gently guide the narrative towards a moment of awareness or simple observation related to the user's input. Describe a sensory detail or a simple action mindfully.
3.  **Comment/Feedback (`comment`):** Offer a short, calming reflection in {commentLang} related to the story or input. It could be a gentle reminder to breathe or notice something simple. Example: "A quiet moment. Take a breath... what do you notice around the character right now? Even small details matter."
4.  **Hint (`hint`):** The hint should guide the user towards a mindful action or observation within the story. Example: "What happens next? (e.g. 'They pause and listen to the sounds around them', 'They focus on the feeling of the ground beneath their feet', 'They simply watch a leaf fall')"
5.  **JSON Structure:** Strictly maintain the JSON structure `{"integratedStory": "...", "comment": "...", "hint": "..."}`.
        </textarea>
      </div>
      <div id="historicalwhatifPromptSection" class="theme-instructions">
         <label>Additional Instruction for "Historical What-If":</label>
         <textarea id="historicalwhatifPrompt" rows="12" readonly>
# Special instructions for the theme "Historical What-If":
1.  **Context:** Assume the story starts with or involves a specific historical setting or event.
2.  **Story Integration (`integratedStory`):** Explore the immediate consequences of the user's input within the established historical context. How does the timeline diverge?
3.  **Comment/Feedback (`comment`):** Provide a comment in {commentLang} that reflects (perhaps ironically) on the historical plausibility or the potential ramifications of the user's alternate history choice. Example: "Interesting turn! If that *had* happened in 1688, the price of tea might be very different today, wouldn't it?"
4.  **Hint (`hint`):** The hint should prompt the user to consider the next logical (or perhaps illogical but fun) consequence in this alternate timeline. Example: "What is the immediate result? (e.g. 'A rival faction reacts to this change', 'A new technology emerges because of this', 'Pigeons are suddenly declared the ruling class')"
5.  **JSON Structure:** Strictly maintain the JSON structure `{"integratedStory": "...", "comment": "...", "hint": "..."}`.
        </textarea>
      </div>
      <!-- End Theme Instructions -->
      <div>
        <label id="themeLabel" for="themeSelect">Theme (optional):</label>
        <select id="themeSelect">
          <option value="standard">Standard</option>
          <option value="romantik">Romance</option>
          <option value="nachhaltig">Sustainable</option>
          <option value="physik">Physics</option>
          <option value="lustig">Funny</option>
          <option value="scifi">Sci-Fi</option>
          <option value="fantasy">Fantasy</option>
          <option value="german-a2">Learn German A2</option>
          <option value="lifecoach">Lifecoach (Playful)</option>
          <option value="creative-writing">Creative Writing Assistant</option>
          <option value="mindfulness">Mindfulness Moment</option>
          <option value="historical-whatif">Historical What-If</option>
        </select>
      </div>
      <hr>
      <h3 id="otherSettingsTitle">Other Settings</h3>
      <div>
        <label id="autoStartTimeLabel" for="autoStartTime">Auto-Start Time (HH:MM):</label>
        <input type="time" id="autoStartTime" value="17:00">
      </div>
      <div>
        <label id="useBrowserSttText">Using browser's speech recognition for voice input</label>
      </div>
      <div>
        <label><input type="checkbox" id="showHelpInfos"> <span id="showDebugInfoText">Show debug info for API requests</span></label>
      </div>
      <div id="modelInfoSettings" class="modelInfo">
        Using models: STT: whisper-1 | TTS: Browser SpeechSynthesis
      </div>
      <h3 id="debugLogTitle">Debug Log</h3>
      <div id="debugLog"></div>
      <button id="copyDebugBtn">Copy Debug Log</button>
      <button id="clearDebugBtn">Clear Debug Log</button>
    </div>
  </div>

  <!-- Contributions Modal -->
  <div id="contributionsModal" class="modal">
    <div class="modal-content">
      <span class="close" id="contribsClose">√ó</span>
      <h2 id="allContributionsTitle">All User Contributions</h2>
      <ul id="contribList"></ul>
    </div>
  </div>

  <script>
    /* Global Variables */
    let apiKey = localStorage.getItem("openrouter_api_key") || "";
    let googleApiKey = localStorage.getItem("google_api_key") || ""; // New
    let gameActive = false;
    let fullStory = ""; let currentHint = ""; let lastComment = ""; let lastUserInput = "";
    let mediaRecorder; let audioChunks = []; let recordCountdownInterval;
    const RECORD_TIME = 20; let userContributions = [];
    let currentLanguage = localStorage.getItem("story_language") || "de";
    let currentTtsProvider = localStorage.getItem("tts_provider") || "browser"; // New
    let useBrowserSTT = true; // Always use browser STT
    let recognitionInstance = null; // Speech recognition instance

    const languageNameMap = { de: "Deutsch", en: "English", ru: "Russisch" };
    const googleLangCodeMap = { de: 'de-DE', en: 'en-US', ru: 'ru-RU' }; // New

    // UI Translations
    const uiTranslations = {
        en: {
            appTitle: "Interactive Story App",
            startGame: "Start Game",
            restartGame: "Restart Game",
            stopGame: "Stop Game",
            settings: "Settings & Debug",
            showContribs: "Show Contributions",
            stopSpeaking: "Stop Speaking",
            processing: "Processing request... Please wait.",
            lastUserInput: "Last User Input (Transcript)",
            noInputYet: "No input yet.",
            commentFeedback: "Comment / Feedback",
            waitingForContribution: "Waiting for the first contribution...",
            currentStory: "Current Story",
            noStoryStarted: "No story started yet.",
            hint: "Hint",
            startHint: "Start the game to get a hint.",
            startRecording: "Start Recording",
            stopRecording: "Stop Recording",
            openRouterNote: "Note: This app now uses Open Router for LLM API calls instead of OpenAI directly.",
            apiKeyLabel: "Open Router API Key:",
            apiKeyPlaceholder: "Enter Open Router API key here (sk-...)",
            modelSelectLabel: "Open Router Model (Free Options):",
            interfaceLanguage: "Interface & TTS Language:",
            ttsSettings: "Text-to-Speech (TTS) Settings",
            ttsProvider: "TTS Provider:",
            storyGenSettings: "Story Generation Settings",
            initialPrompt: "Initial Prompt (Story Start):",
            reactionPrompt: "Reaction Prompt (Integration & Comment):",
            themeLabel: "Theme (optional):",
            otherSettings: "Other Settings",
            autoStartTime: "Auto-Start Time (HH:MM):",
            useBrowserStt: "Using browser's speech recognition for voice input",
            showDebugInfo: "Show debug info for API requests",
            debugLog: "Debug Log",
            copyDebug: "Copy Debug Log",
            clearDebug: "Clear Debug Log",
            allContributions: "All User Contributions",
            noContributions: "No contributions yet.",
            gameInactive: "Game stopped."
        },
        de: {
            appTitle: "Interaktive Geschichten-App",
            startGame: "Spiel starten",
            restartGame: "Spiel neu starten",
            stopGame: "Spiel beenden",
            settings: "Einstellungen & Debug",
            showContribs: "Beitr√§ge anzeigen",
            stopSpeaking: "Sprechen beenden",
            processing: "Verarbeite Anfrage... Bitte warten.",
            lastUserInput: "Letzter Benutzerbeitrag (Transkript)",
            noInputYet: "Noch keine Eingabe.",
            commentFeedback: "Kommentar / Feedback",
            waitingForContribution: "Warte auf den ersten Beitrag...",
            currentStory: "Aktuelle Geschichte",
            noStoryStarted: "Noch keine Geschichte begonnen.",
            hint: "Hinweis",
            startHint: "Starte das Spiel, um einen Hinweis zu erhalten.",
            startRecording: "Aufnahme starten",
            stopRecording: "Aufnahme beenden",
            openRouterNote: "Hinweis: Diese App verwendet jetzt Open Router f√ºr LLM-API-Aufrufe anstelle von OpenAI direkt.",
            apiKeyLabel: "Open Router API-Schl√ºssel:",
            apiKeyPlaceholder: "Open Router API-Schl√ºssel hier eingeben (sk-...)",
            modelSelectLabel: "Open Router Modell (Kostenlose Optionen):",
            interfaceLanguage: "Oberfl√§chen- & TTS-Sprache:",
            ttsSettings: "Text-zu-Sprache (TTS) Einstellungen",
            ttsProvider: "TTS-Anbieter:",
            storyGenSettings: "Einstellungen zur Geschichtengenerierung",
            initialPrompt: "Anfangsprompt (Geschichtenanfang):",
            reactionPrompt: "Reaktionsprompt (Integration & Kommentar):",
            themeLabel: "Thema (optional):",
            otherSettings: "Weitere Einstellungen",
            autoStartTime: "Auto-Start-Zeit (HH:MM):",
            useBrowserStt: "Verwendet Spracherkennung des Browsers f√ºr Spracheingabe",
            showDebugInfo: "Debug-Infos f√ºr API-Anfragen anzeigen",
            debugLog: "Debug-Protokoll",
            copyDebug: "Debug-Protokoll kopieren",
            clearDebug: "Debug-Protokoll l√∂schen",
            allContributions: "Alle Benutzerbeitr√§ge",
            noContributions: "Noch keine Beitr√§ge.",
            gameInactive: "Spiel angehalten."
        },
        ru: {
            appTitle: "–ü—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–æ–π –∏—Å—Ç–æ—Ä–∏–∏",
            startGame: "–ù–∞—á–∞—Ç—å –∏–≥—Ä—É",
            restartGame: "–ü–µ—Ä–µ–∑–∞–ø—É—Å—Ç–∏—Ç—å –∏–≥—Ä—É",
            stopGame: "–û—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –∏–≥—Ä—É",
            settings: "–ù–∞—Å—Ç—Ä–æ–π–∫–∏ –∏ –æ—Ç–ª–∞–¥–∫–∞",
            showContribs: "–ü–æ–∫–∞–∑–∞—Ç—å –≤–∫–ª–∞–¥—ã",
            stopSpeaking: "–û—Å—Ç–∞–Ω–æ–≤–∏—Ç—å —Ä–µ—á—å",
            processing: "–û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–ø—Ä–æ—Å–∞... –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø–æ–¥–æ–∂–¥–∏—Ç–µ.",
            lastUserInput: "–ü–æ—Å–ª–µ–¥–Ω–∏–π –≤–≤–æ–¥ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è (—Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç)",
            noInputYet: "–ï—â–µ –Ω–µ—Ç –≤–≤–æ–¥–∞.",
            commentFeedback: "–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π / –û–±—Ä–∞—Ç–Ω–∞—è —Å–≤—è–∑—å",
            waitingForContribution: "–û–∂–∏–¥–∞–Ω–∏–µ –ø–µ—Ä–≤–æ–≥–æ –≤–∫–ª–∞–¥–∞...",
            currentStory: "–¢–µ–∫—É—â–∞—è –∏—Å—Ç–æ—Ä–∏—è",
            noStoryStarted: "–ò—Å—Ç–æ—Ä–∏—è –µ—â–µ –Ω–µ –Ω–∞—á–∞—Ç–∞.",
            hint: "–ü–æ–¥—Å–∫–∞–∑–∫–∞",
            startHint: "–ù–∞—á–Ω–∏—Ç–µ –∏–≥—Ä—É, —á—Ç–æ–±—ã –ø–æ–ª—É—á–∏—Ç—å –ø–æ–¥—Å–∫–∞–∑–∫—É.",
            startRecording: "–ù–∞—á–∞—Ç—å –∑–∞–ø–∏—Å—å",
            stopRecording: "–û—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –∑–∞–ø–∏—Å—å",
            openRouterNote: "–ü—Ä–∏–º–µ—á–∞–Ω–∏–µ: –≠—Ç–æ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ —Ç–µ–ø–µ—Ä—å –∏—Å–ø–æ–ª—å–∑—É–µ—Ç Open Router –¥–ª—è LLM API –≤—ã–∑–æ–≤–æ–≤ –≤–º–µ—Å—Ç–æ OpenAI –Ω–∞–ø—Ä—è–º—É—é.",
            apiKeyLabel: "–ö–ª—é—á API Open Router:",
            apiKeyPlaceholder: "–í–≤–µ–¥–∏—Ç–µ –∫–ª—é—á API Open Router –∑–¥–µ—Å—å (sk-...)",
            modelSelectLabel: "–ú–æ–¥–µ–ª—å Open Router (–ë–µ—Å–ø–ª–∞—Ç–Ω—ã–µ –æ–ø—Ü–∏–∏):",
            interfaceLanguage: "–Ø–∑—ã–∫ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞ –∏ TTS:",
            ttsSettings: "–ù–∞—Å—Ç—Ä–æ–π–∫–∏ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è —Ç–µ–∫—Å—Ç–∞ –≤ —Ä–µ—á—å (TTS)",
            ttsProvider: "–ü—Ä–æ–≤–∞–π–¥–µ—Ä TTS:",
            storyGenSettings: "–ù–∞—Å—Ç—Ä–æ–π–∫–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏—Å—Ç–æ—Ä–∏–∏",
            initialPrompt: "–ù–∞—á–∞–ª—å–Ω—ã–π –∑–∞–ø—Ä–æ—Å (–ù–∞—á–∞–ª–æ –∏—Å—Ç–æ—Ä–∏–∏):",
            reactionPrompt: "–ó–∞–ø—Ä–æ—Å —Ä–µ–∞–∫—Ü–∏–∏ (–ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è –∏ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π):",
            themeLabel: "–¢–µ–º–∞ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ):",
            otherSettings: "–î—Ä—É–≥–∏–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏",
            autoStartTime: "–í—Ä–µ–º—è –∞–≤—Ç–æ–∑–∞–ø—É—Å–∫–∞ (–ß–ß:–ú–ú):",
            useBrowserStt: "–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Ä–µ—á–∏ –±—Ä–∞—É–∑–µ—Ä–∞ –¥–ª—è –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ –≤–≤–æ–¥–∞",
            showDebugInfo: "–ü–æ–∫–∞–∑–∞—Ç—å –æ—Ç–ª–∞–¥–æ—á–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –¥–ª—è API –∑–∞–ø—Ä–æ—Å–æ–≤",
            debugLog: "–ñ—É—Ä–Ω–∞–ª –æ—Ç–ª–∞–¥–∫–∏",
            copyDebug: "–ö–æ–ø–∏—Ä–æ–≤–∞—Ç—å –∂—É—Ä–Ω–∞–ª –æ—Ç–ª–∞–¥–∫–∏",
            clearDebug: "–û—á–∏—Å—Ç–∏—Ç—å –∂—É—Ä–Ω–∞–ª –æ—Ç–ª–∞–¥–∫–∏",
            allContributions: "–í—Å–µ –≤–∫–ª–∞–¥—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è",
            noContributions: "–í–∫–ª–∞–¥–æ–≤ –ø–æ–∫–∞ –Ω–µ—Ç.",
            gameInactive: "–ò–≥—Ä–∞ –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞."
        }
    };
    
    // Get translated text
    function getTranslation(key) {
        const lang = currentLanguage || 'en';
        return uiTranslations[lang][key] || uiTranslations['en'][key] || key;
    }

    let isProcessing = false; let isSpeaking = false;
    let currentAudioElement = null; let apiCountdownInterval;
    const ESTIMATED_API_TIME = 25;

    let currentSTTModel = "whisper-1";
    let currentLLMModel = localStorage.getItem("openrouter_model") || "google/gemini-2.0-flash-exp:free"; let currentTTSModel = "Browser TTS"; // Will be updated

    let lastStartRequest = "", lastStartResponse = ""; let lastReactionRequest = "", lastReactionResponse = "";

    // --- DOM Element Caching ---
    // (Assuming IDs match HTML, simplified for brevity)
    const startGameBtn = document.getElementById("startGameBtn");
    const restartGameBtn = document.getElementById("restartGameBtn");
    const stopGameBtn = document.getElementById("stopGameBtn");
    const settingsBtn = document.getElementById("settingsBtn");
    const showContribsBtn = document.getElementById("showContribsBtn");
    const stopTTSBtn = document.getElementById("stopTTSBtn");
    const modelInfoDiv = document.getElementById("modelInfo");
    const loadingIndicator = document.getElementById("loadingIndicator");
    const apiCountdownSpan = document.getElementById("apiCountdown");
    const recordCountdownDiv = document.getElementById("recordCountdown");
    const recordButtonsDiv = document.getElementById("recordButtons");
    const startRecordBtn = document.getElementById("startRecordBtn");
    const stopRecordBtn = document.getElementById("stopRecordBtn");
    const useBrowserSTTCheckbox = document.getElementById("useBrowserSTT");
    const lastUserInputTitle = document.querySelector("#benutzerBeitrag h2");
    const lastUserTextDiv = document.getElementById("lastUserText");
    const commentTitle = document.querySelector("#ironicCommentSection h2");
    const ironicTextDiv = document.getElementById("ironicText");
    const storyTitle = document.querySelector("#currentStory h2");
    const storyTextDiv = document.getElementById("storyText");
    const hintTitle = document.querySelector("#nextHint h2");
    const hintTextDiv = document.getElementById("hintText");
    // Modals
    const settingsModal = document.getElementById("settingsModal");
    const settingsClose = document.getElementById("settingsClose");
    const contributionsModal = document.getElementById("contributionsModal");
    const contribsClose = document.getElementById("contribsClose");
    const contributionsTitle = document.querySelector("#contributionsModal h2");
    const contribList = document.getElementById("contribList");
    // Settings Inputs
    const apiKeyInput = document.getElementById("apiKey");
    const modelSelect = document.getElementById("modelSelect");
    const languageSelect = document.getElementById("languageSelect");
    const initialPromptInput = document.getElementById("initialPrompt");
    const reactionPromptInput = document.getElementById("reactionPrompt");
    // Theme Prompts
    const germanA2PromptSection = document.getElementById("germanA2PromptSection");
    const germanA2Prompt = document.getElementById("germanA2Prompt");
    const lifecoachPromptSection = document.getElementById("lifecoachPromptSection");
    const lifecoachPrompt = document.getElementById("lifecoachPrompt");
    const creativewritingPromptSection = document.getElementById("creativewritingPromptSection");
    const creativewritingPrompt = document.getElementById("creativewritingPrompt");
    const mindfulnessPromptSection = document.getElementById("mindfulnessPromptSection");
    const mindfulnessPrompt = document.getElementById("mindfulnessPrompt");
    const historicalwhatifPromptSection = document.getElementById("historicalwhatifPromptSection");
    const historicalwhatifPrompt = document.getElementById("historicalwhatifPrompt");
    const themeSelect = document.getElementById("themeSelect");
    // TTS Settings
    const ttsProviderSelect = document.getElementById("ttsProviderSelect"); // New
    const elevenlabsSettingsDiv = document.getElementById("elevenlabsSettings"); // New
    const elevenLabsKeyInput = document.getElementById("elevenLabsKey");
    const elevenLabsVoiceInput = document.getElementById("elevenLabsVoice");
    const googleTtsSettingsDiv = document.getElementById("googleTtsSettings"); // New
    const googleApiKeyInput = document.getElementById("googleApiKey"); // New
    const googleVoiceNameInput = document.getElementById("googleVoiceName"); // New
    const ttsStyleInput = document.getElementById("ttsStyle");
    // Other Settings
    const autoStartTimeInput = document.getElementById("autoStartTime");
    const showHelpInfosCheckbox = document.getElementById("showHelpInfos");
    const modelInfoSettingsDiv = document.getElementById("modelInfoSettings");
    const debugLogDiv = document.getElementById("debugLog");
    const copyDebugBtn = document.getElementById("copyDebugBtn");
    const clearDebugBtn = document.getElementById("clearDebugBtn");
    const storyDebugDiv = document.getElementById("storyDebug");
    const hintDebugDiv = document.getElementById("hintDebug");

    // --- Initialization & Event Listeners ---

    document.addEventListener('DOMContentLoaded', () => {
        apiKeyInput.value = apiKey;
        modelSelect.value = currentLLMModel;
        googleApiKeyInput.value = googleApiKey; // Load Google Key
        languageSelect.value = currentLanguage;
        ttsProviderSelect.value = currentTtsProvider; // Load TTS Provider pref
        elevenLabsKeyInput.value = localStorage.getItem("elevenlabs_key") || "";
        elevenLabsVoiceInput.value = localStorage.getItem("elevenlabs_voice") || "";
        googleVoiceNameInput.value = localStorage.getItem("google_voice_name") || ""; // Load Google Voice pref
        // Browser STT is always enabled
        handleTtsProviderChange(); // Show relevant TTS settings
        handleThemeChange(); // Show relevant theme prompt
        updateUILanguage(); // Update UI with translations
        debugLog("Application initialized.");
        updateUIState();
        updateModelInfo(); // Update based on loaded provider pref
    });

    // --- Event Listeners Setup ---
    function setupEventListeners() {
        settingsBtn.addEventListener("click", () => openModal("settingsModal"));
        settingsClose.addEventListener("click", () => closeModal("settingsModal"));
        showContribsBtn.addEventListener("click", () => { updateContribsModal(); openModal("contributionsModal"); });
        contribsClose.addEventListener("click", () => closeModal("contributionsModal"));
        startGameBtn.addEventListener("click", () => { if (isProcessing || isSpeaking) { alert("Please wait..."); return; } debugLog("Start Game clicked."); startGame(); });
        restartGameBtn.addEventListener("click", () => { if (isProcessing || isSpeaking) { alert("Please wait..."); return; } debugLog("Restart Game clicked."); restartGame(); });
        stopGameBtn.addEventListener("click", () => { if (isProcessing) { alert("Please wait..."); return; } debugLog("Stop Game clicked."); stopGame(); });
        startRecordBtn.addEventListener("click", () => { if (isProcessing || isSpeaking) { alert("Please wait..."); return; } debugLog("Start Rec clicked."); recordUserSpeech(); });
        stopRecordBtn.addEventListener("click", () => { debugLog("Stop Rec clicked."); stopRecording(); });
        stopTTSBtn.addEventListener("click", () => { debugLog("Stop TTS clicked."); stopSpeaking(); });

        // Settings listeners
        apiKeyInput.addEventListener("change", () => { 
            apiKey = apiKeyInput.value.trim(); 
            localStorage.setItem("openrouter_api_key", apiKey); 
            updateModelInfo();
            debugLog("OpenAI Key " + (apiKey ? "saved." : "removed.") + (useBrowserSTT ? " Using browser STT." : "")); 
        });
        googleApiKeyInput.addEventListener("change", () => { googleApiKey = googleApiKeyInput.value.trim(); localStorage.setItem("google_api_key", googleApiKey); debugLog("Google API Key " + (googleApiKey ? "saved." : "removed.")); });
        languageSelect.addEventListener("change", () => { 
            currentLanguage = languageSelect.value; 
            localStorage.setItem("story_language", currentLanguage); 
            handleThemeChange(); 
            updateUILanguage(); // Update UI text with new language
            debugLog(`Lang changed to: ${currentLanguage}`); 
        });
        themeSelect.addEventListener("change", handleThemeChange);
        ttsProviderSelect.addEventListener("change", handleTtsProviderChange); // Listener for provider change
        elevenLabsKeyInput.addEventListener("change", () => { localStorage.setItem("elevenlabs_key", elevenLabsKeyInput.value.trim()); debugLog("ElevenLabs Key saved."); });
        elevenLabsVoiceInput.addEventListener("change", () => { localStorage.setItem("elevenlabs_voice", elevenLabsVoiceInput.value.trim()); debugLog("ElevenLabs Voice saved."); });
        googleVoiceNameInput.addEventListener("change", () => { localStorage.setItem("google_voice_name", googleVoiceNameInput.value.trim()); debugLog("Google Voice saved."); });
        useBrowserSTTCheckbox.addEventListener("change", () => { 
            useBrowserSTT = useBrowserSTTCheckbox.checked; 
            localStorage.setItem("use_browser_stt", useBrowserSTT); 
            updateModelInfo();
            debugLog("Browser STT " + (useBrowserSTT ? "enabled." : "disabled.")); 
        });

        // Debug listeners
        copyDebugBtn.addEventListener("click", () => { navigator.clipboard.writeText(debugLogDiv.innerText).then(() => { debugLog("Log copied."); alert("Log copied!"); }).catch(err => { debugLog(`Copy error: ${err}`); alert("Copy failed."); }); });
        clearDebugBtn.addEventListener("click", () => { debugLogDiv.innerHTML = ""; debugLog("Log cleared."); });
        showHelpInfosCheckbox.addEventListener("change", updateHelpInfosVisibility);
    }
    setupEventListeners();

     // Show/Hide TTS Provider settings
     function handleTtsProviderChange() {
        currentTtsProvider = ttsProviderSelect.value;
        localStorage.setItem("tts_provider", currentTtsProvider);
        debugLog(`TTS provider set to: ${currentTtsProvider}`);
        elevenlabsSettingsDiv.style.display = (currentTtsProvider === 'elevenlabs') ? 'block' : 'none';
        googleTtsSettingsDiv.style.display = (currentTtsProvider === 'google') ? 'block' : 'none';
        updateModelInfo(); // Update displayed TTS model name
     }

     // Theme change handler (now includes updating A2 prompt placeholder)
     function handleThemeChange() {
        const sections = [germanA2PromptSection, lifecoachPromptSection, creativewritingPromptSection, mindfulnessPromptSection, historicalwhatifPromptSection];
        sections.forEach(sec => sec.style.display = 'none');
        const selectedTheme = themeSelect.value;
        let relevantSection = null;
        let relevantPromptTextarea = null;
        switch(selectedTheme) {
            case 'german-a2': relevantSection = germanA2PromptSection; relevantPromptTextarea = germanA2Prompt; break;
            case 'lifecoach': relevantSection = lifecoachPromptSection; relevantPromptTextarea = lifecoachPrompt; break;
            case 'creative-writing': relevantSection = creativewritingPromptSection; relevantPromptTextarea = creativewritingPrompt; break;
            case 'mindfulness': relevantSection = mindfulnessPromptSection; relevantPromptTextarea = mindfulnessPrompt; break;
            case 'historical-whatif': relevantSection = historicalwhatifPromptSection; relevantPromptTextarea = historicalwhatifPrompt; break;
        }
        if(relevantSection) {
             relevantSection.style.display = 'block';
             const langName = languageNameMap[currentLanguage] || "the selected language";
             if(relevantPromptTextarea) { relevantPromptTextarea.value = relevantPromptTextarea.value.replace(/in \{commentLang\}/g, `in ${langName}`); }
        }
         debugLog(`Theme changed to: ${selectedTheme}.`);
     }

    // --- Core Logic Functions ---

    function updateUIState() { /* ... (UI state logic as before, using translations) ... */
        if (gameActive) {
            storyTextDiv.textContent = fullStory || getTranslation('noStoryStarted'); 
            hintTextDiv.textContent = currentHint || getTranslation('startHint');
            lastUserTextDiv.textContent = lastUserInput || getTranslation('waitingForContribution'); 
            ironicTextDiv.textContent = lastComment || getTranslation('waitingForContribution');
        } else {
            storyTextDiv.textContent = getTranslation('noStoryStarted'); 
            hintTextDiv.textContent = getTranslation('startHint');
            lastUserTextDiv.textContent = getTranslation('noInputYet'); 
            ironicTextDiv.textContent = getTranslation('gameInactive'); 
            recordCountdownDiv.textContent = "";
        }
        const canRecord = gameActive && !isProcessing && !isSpeaking;
        startGameBtn.disabled = gameActive || isProcessing || isSpeaking; restartGameBtn.disabled = !gameActive || isProcessing || isSpeaking;
        stopGameBtn.disabled = !gameActive || isProcessing; settingsBtn.disabled = isProcessing; showContribsBtn.disabled = isProcessing;
        startRecordBtn.disabled = !canRecord || (mediaRecorder && mediaRecorder.state === "recording");
        stopRecordBtn.disabled = !gameActive || !(mediaRecorder && mediaRecorder.state === "recording"); stopTTSBtn.disabled = !isSpeaking;
    }
    function setProcessingStatus(processing) { /* ... (API countdown logic as before) ... */
        isProcessing = processing; loadingIndicator.style.display = processing ? "block" : "none"; apiCountdownSpan.textContent = "";
        if (processing) { let count = ESTIMATED_API_TIME; apiCountdownSpan.textContent = ` (approx. ${count}s)`; if (apiCountdownInterval) clearInterval(apiCountdownInterval); apiCountdownInterval = setInterval(() => { count--; apiCountdownSpan.textContent = ` (approx. ${count}s)`; if (count <= 0) { clearInterval(apiCountdownInterval); apiCountdownSpan.textContent = ""; }}, 1000); }
        else { if (apiCountdownInterval) clearInterval(apiCountdownInterval); apiCountdownInterval = null; apiCountdownSpan.textContent = ""; } updateUIState();
    }
    function setSpeakingStatus(speaking) { /* ... (Handling isSpeaking flag and buttons as before) ... */
        isSpeaking = speaking; if (!speaking) { if (currentAudioElement) { currentAudioElement.pause(); currentAudioElement = null; } window.speechSynthesis.cancel(); } updateUIState();
    }
    function updateModelInfo() {
        let ttsInfo = "Browser SpeechSynthesis";
        if (currentTtsProvider === 'elevenlabs' && elevenLabsKeyInput.value.trim()) {
            ttsInfo = "ElevenLabs TTS";
        } else if (currentTtsProvider === 'google' && googleApiKeyInput.value.trim() && googleVoiceNameInput.value.trim()) {
            ttsInfo = "Google Cloud TTS";
        }
        let sttInfo = useBrowserSTT ? "Browser SpeechRecognition" : (apiKey ? currentSTTModel : "No API Key");
        let llmInfo = apiKey ? currentLLMModel.split("/").pop() : "No API Key";
        modelInfoDiv.innerHTML = `Using models: STT: ${sttInfo} | LLM: ${llmInfo} | TTS: ${ttsInfo}`;
        modelInfoSettingsDiv.innerHTML = modelInfoDiv.innerHTML;
    }
    function updateHelpInfosVisibility() { /* ... (Visibility logic as before) ... */
        const show = showHelpInfosCheckbox.checked; storyDebugDiv.style.display = show ? "block" : "none"; hintDebugDiv.style.display = show ? "block" : "none"; if(show) updateHelpInfosContent();
    }
    function updateHelpInfosContent() { /* ... (Content update logic as before) ... */
        if (showHelpInfosCheckbox.checked) { storyDebugDiv.innerText = `Last Reaction Req:\n${lastReactionRequest||'N/A'}\n\nLast Reaction Res:\n${lastReactionResponse||'N/A'}`; hintDebugDiv.innerText = `Last Start/Hint Req:\n${lastStartRequest||lastReactionRequest||'N/A'}\n\nLast Start/Hint Res:\n${lastStartResponse||lastReactionResponse||'N/A'}`; }
    }
    function safeParseJSON(text) { /* ... (Parsing logic as before) ... */
        try { return JSON.parse(text); } catch (e) { debugLog(`Std JSON parse failed: ${e}. Extracting...`); const s=text.indexOf('{'), end=text.lastIndexOf('}'); if (s !== -1 && end !== -1 && end > s) { const json = text.substring(s, end + 1); try { const p = JSON.parse(json); debugLog("JSON extracted ok."); return p; } catch (e2) { debugLog(`Extraction parse error: ${e2}.`); return null; }} else { debugLog(`No JSON structure found.`); return null; } }
    }
    function removeDuplicatePhrases(text) { /* ... (Logic as before) ... */
        const l=text.length; if (l > 10 && text.substring(0, l/2).trim() === text.substring(l/2).trim()) { debugLog("Shortened repeat transcript."); return text.substring(0, l/2).trim(); } return text;
    }
    function debugLog(message) { const ts = new Date().toISOString(); const msg = `[${ts}] ${message}`; debugLogDiv.innerHTML = `${msg}<br>` + debugLogDiv.innerHTML; console.log(msg); }
    function openModal(id) { document.getElementById(id).style.display = "block"; debugLog(`Modal ${id} opened.`); }
    function closeModal(id) { document.getElementById(id).style.display = "none"; debugLog(`Modal ${id} closed.`); }

    // --- Game Flow Functions ---
    async function startGame() { /* ... (Start game logic as before) ... */
        if (!apiKey) { alert("Please enter API Key in settings."); openModal("settingsModal"); return; }
        if (!navigator.mediaDevices?.getUserMedia) { alert("MediaDevices API not supported."); return; }
        setProcessingStatus(true);
        try {
            gameActive = true; fullStory = ""; currentHint = ""; lastComment = ""; lastUserInput = ""; userContributions = [];
            lastStartRequest = ""; lastStartResponse = ""; lastReactionRequest = ""; lastReactionResponse = "";
            recordButtonsDiv.style.display = "block"; updateUIState();
            lastUserTextDiv.textContent = "Waiting for first contribution..."; ironicTextDiv.textContent = "Waiting for first contribution...";
            debugLog("Starting game...");
            const initialData = await fetchBotStart(); setProcessingStatus(false);
            if (initialData) {
                fullStory = initialData.startSentence || "Error."; currentHint = initialData.hint || "Error.";
                storyTextDiv.textContent = fullStory; hintTextDiv.textContent = currentHint;
                updateHelpInfosContent(); debugLog("Initial story loaded.");
                setSpeakingStatus(true);
                try { await speakText(fullStory, currentLanguage); if (isSpeaking) await new Promise(r => setTimeout(r, 300)); if (isSpeaking) await speakText(currentHint, currentLanguage); }
                catch (err) { if (err !== "Cancelled") debugLog(`TTS startup err: ${err}`); } finally { setSpeakingStatus(false); }
                debugLog("Game started successfully.");
            } else { storyTextDiv.textContent = "Error starting game."; hintTextDiv.textContent = ""; gameActive = false; recordButtonsDiv.style.display = "none"; updateUIState(); }
        } catch(error) { debugLog(`startGame Err: ${error}`); alert("Error starting."); gameActive = false; recordButtonsDiv.style.display = "none"; setProcessingStatus(false); updateUIState(); }
    }
    function restartGame() { debugLog("Restarting game..."); stopGame(); setTimeout(startGame, 500); }
    function stopGame() { /* ... (Stop game logic as before) ... */
        gameActive = false; stopRecording(); stopSpeaking(); if (apiCountdownInterval) clearInterval(apiCountdownInterval);
        recordButtonsDiv.style.display = "none"; recordCountdownDiv.textContent = ""; setProcessingStatus(false);
        fullStory = ""; currentHint = ""; lastComment = ""; lastUserInput = ""; userContributions = [];
        debugLog("Game stopped."); updateUIState();
    }

    // --- Recording Functions ---
    async function recordUserSpeech() {
        if (!gameActive) { debugLog("Record attempt while inactive."); return; }
        
        // Use browser's speech recognition if enabled or no API key available
        if (useBrowserSTT || !apiKey) {
            recordWithBrowserSTT();
            return;
        }
        
        // Otherwise use the original recording logic with OpenAI API
        setProcessingStatus(true); 
        let stream; 
        try { 
            stream = await navigator.mediaDevices.getUserMedia({ audio: true }); 
            debugLog("Mic ok."); 
        } catch (err) { 
            alert("Mic access denied."); 
            debugLog(`Mic err: ${err}`); 
            setProcessingStatus(false); 
            return; 
        } 
        setProcessingStatus(false);
        
        audioChunks = []; 
        const mTypes = ['audio/webm;codecs=opus', 'audio/ogg;codecs=opus', 'audio/wav']; 
        const supType = mTypes.find(t => MediaRecorder.isTypeSupported(t)); 
        debugLog(`Mime: ${supType || 'Default'}`);
        
        try { 
            mediaRecorder = new MediaRecorder(stream, { mimeType: supType || undefined }); 
        } catch (e) { 
            debugLog(`Recorder err: ${e}`); 
            alert("Recording init err."); 
            return; 
        }
        
        mediaRecorder.ondataavailable = e => { 
            if (e.data.size > 0) audioChunks.push(e.data); 
        };
        
        mediaRecorder.onstop = async () => {
            setProcessingStatus(true);
            try {
                if (recordCountdownInterval) clearInterval(recordCountdownInterval); 
                recordCountdownDiv.textContent = ""; 
                stream.getTracks().forEach(t => t.stop()); 
                debugLog("Recording stopped.");
                
                if (audioChunks.length === 0) { 
                    debugLog("No audio."); 
                    return; 
                }
                
                const blob = new Blob(audioChunks, { type: supType || 'audio/wav' }); 
                const fName = `userSpeech.${(supType || 'wav').split('/')[1].split(';')[0] || 'wav'}`;
                debugLog(`Blob (${(blob.size/1024).toFixed(1)} KB). Transcribing...`); 
                audioChunks = [];
                
                let transcript = await sendAudioToTranscribe(blob, fName);
                if (transcript && transcript.trim()) { 
                    transcript = removeDuplicatePhrases(transcript.trim()); 
                    lastUserInput = transcript; 
                    lastUserTextDiv.textContent = transcript; 
                    debugLog("Transcript: " + transcript); 
                    await processUserInput(transcript); 
                } else { 
                    debugLog("Empty transcript."); 
                    lastUserInput = ""; 
                    lastUserTextDiv.textContent = "(Empty input)"; 
                    ironicTextDiv.textContent = "Couldn't understand."; 
                    setProcessingStatus(false); 
                    setSpeakingStatus(true); 
                    try { 
                        await speakText("Sorry, I couldn't understand.", currentLanguage); 
                    } catch (err) { 
                        if (err !== "Cancelled") debugLog(`TTS Err: ${err}`); 
                    } finally { 
                        setSpeakingStatus(false); 
                    } 
                }
            } catch (err) { 
                debugLog(`Record stop/process err: ${err}`); 
                alert("Error processing recording."); 
            } finally { 
                setProcessingStatus(false); 
            }
        };
        
        mediaRecorder.start(); 
        debugLog("Recording started."); 
        updateUIState(); 
        let rem = RECORD_TIME; 
        recordCountdownDiv.textContent = `Recording... (${rem}s)`; 
        if (recordCountdownInterval) clearInterval(recordCountdownInterval); 
        recordCountdownInterval = setInterval(() => { 
            rem--; 
            recordCountdownDiv.textContent = `Recording... (${rem}s)`; 
            if (rem <= 0) { 
                debugLog("Max time."); 
                stopRecording(); 
            }
        }, 1000);
    }
    
    // Function to record using browser's Speech Recognition API
    function recordWithBrowserSTT() {
        if (!('SpeechRecognition' in window || 'webkitSpeechRecognition' in window)) {
            alert("Your browser doesn't support speech recognition. Try using Chrome, Edge, or Safari.");
            debugLog("Browser speech recognition not supported.");
            return;
        }
        
        try {
            const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
            recognitionInstance = new SpeechRecognition();
            
            // Configure the recognition
            recognitionInstance.lang = googleLangCodeMap[currentLanguage] || 'en-US';
            recognitionInstance.continuous = false;
            recognitionInstance.interimResults = false;
            recognitionInstance.maxAlternatives = 1;
            
            // Update UI
            setProcessingStatus(true);
            recordCountdownDiv.textContent = "Listening... (click Stop when finished)";
            debugLog("Browser STT: Started listening...");
            updateUIState();
            
            // Set up event listeners
            recognitionInstance.onresult = async (event) => {
                const transcript = event.results[0][0].transcript;
                debugLog(`Browser STT result: ${transcript}`);
                
                if (transcript && transcript.trim()) {
                    const cleanedTranscript = removeDuplicatePhrases(transcript.trim());
                    lastUserInput = cleanedTranscript;
                    lastUserTextDiv.textContent = cleanedTranscript;
                    await processUserInput(cleanedTranscript);
                } else {
                    debugLog("Empty transcript from browser STT.");
                    lastUserInput = "";
                    lastUserTextDiv.textContent = "(Empty input)";
                    ironicTextDiv.textContent = "Couldn't understand.";
                    setProcessingStatus(false);
                    setSpeakingStatus(true);
                    try {
                        await speakText("Sorry, I couldn't understand.", currentLanguage);
                    } catch (err) {
                        if (err !== "Cancelled") debugLog(`TTS Err: ${err}`);
                    } finally {
                        setSpeakingStatus(false);
                    }
                }
            };
            
            recognitionInstance.onerror = (event) => {
                debugLog(`Browser STT error: ${event.error}`);
                setProcessingStatus(false);
                recordCountdownDiv.textContent = "";
                updateUIState();
                
                if (event.error === 'no-speech') {
                    alert("No speech detected. Please try again.");
                } else if (event.error !== 'aborted') {
                    alert(`Speech recognition error: ${event.error}`);
                }
            };
            
            recognitionInstance.onend = () => {
                debugLog("Browser STT: Recognition ended.");
                setProcessingStatus(false);
                recordCountdownDiv.textContent = "";
                updateUIState();
                recognitionInstance = null;
            };
            
            // Start recognition
            recognitionInstance.start();
            
        } catch (error) {
            debugLog(`Browser STT init error: ${error}`);
            alert("Error initializing speech recognition. Try again or check browser compatibility.");
            setProcessingStatus(false);
            recordCountdownDiv.textContent = "";
            updateUIState();
        }
    }
    function stopRecording() {
        // If using browser STT
        if (recognitionInstance) {
            recognitionInstance.stop();
            debugLog("Browser STT: stopping recognition");
            return;
        }
        
        // Regular MediaRecorder logic
        if (mediaRecorder?.state === "recording") { 
            mediaRecorder.stop(); 
            debugLog("stopRecording called."); 
        } else { 
            debugLog("stopRecording: recorder inactive."); 
            if (recordCountdownInterval) clearInterval(recordCountdownInterval); 
            recordCountdownDiv.textContent = ""; 
            updateUIState(); 
        }
    }

    // --- TTS Functions ---
    function stopSpeaking() { /* ... (Stop speaking logic as before) ... */
         debugLog("Stopping speech..."); window.speechSynthesis.cancel(); if (currentAudioElement) { currentAudioElement.pause(); currentAudioElement.src = ""; currentAudioElement = null; debugLog("ElevenLabs stopped."); } setSpeakingStatus(false);
    }

    // Helper to convert Base64 to Blob
    async function base64ToBlob(base64, contentType = 'audio/mp3') {
        try {
            const byteCharacters = atob(base64);
            const byteNumbers = new Array(byteCharacters.length);
            for (let i = 0; i < byteCharacters.length; i++) {
                byteNumbers[i] = byteCharacters.charCodeAt(i);
            }
            const byteArray = new Uint8Array(byteNumbers);
            return new Blob([byteArray], {type: contentType});
        } catch (e) {
            debugLog("Error decoding Base64: " + e);
            return null;
        }
    }


    async function speakText(text, lang) {
        if (!text || !isSpeaking) { debugLog("speakText skipped."); return Promise.resolve(); }
        const targetLang = lang || currentLanguage;
        debugLog(`speakText executing (Lang: ${targetLang}, Provider: ${currentTtsProvider}). Text: "${text.substring(0, 50)}..."`);
        const ttsStyle = ttsStyleInput.value || "A clear, neutral voice."; // Style might have minimal effect

        // --- Provider Logic ---
        if (currentTtsProvider === 'google') {
            const googleKey = googleApiKeyInput.value.trim();
            const googleVoice = googleVoiceNameInput.value.trim();
            if (googleKey && googleVoice) {
                currentTTSModel = "Google Cloud TTS"; updateModelInfo();
                debugLog(`Attempting speech with Google TTS (Voice: ${googleVoice}, Lang: ${targetLang}).`);
                try {
                    const googleLangCode = googleLangCodeMap[targetLang] || 'en-US'; // Map to Google codes
                    const requestBody = {
                        input: { text: text },
                        voice: { languageCode: googleLangCode, name: googleVoice },
                        audioConfig: { audioEncoding: "MP3", speakingRate: 1.0 } // Adjust speakingRate if desired
                    };
                    // Use query parameter for API key (simpler for client-side, **less secure**)
                    const response = await fetch(`https://texttospeech.googleapis.com/v1/text:synthesize?key=${googleKey}`, {
                        method: "POST",
                        headers: { "Content-Type": "application/json" },
                        body: JSON.stringify(requestBody)
                    });
                    if (!response.ok) { let eD=null; try{eD=await response.json();}catch(e){} throw new Error(`Google TTS API Error: ${eD?.error?.message || response.status}`); }
                    const data = await response.json();
                    if (data.audioContent) {
                        const audioBlob = await base64ToBlob(data.audioContent, 'audio/mp3');
                        if (!audioBlob) throw new Error("Failed to decode Google audio content.");
                        const audioUrl = URL.createObjectURL(audioBlob);
                        if (!isSpeaking) { URL.revokeObjectURL(audioUrl); return Promise.reject("Cancelled"); }
                        currentAudioElement = new Audio(audioUrl); debugLog("Google TTS audio playing...");
                        await new Promise((resolve, reject) => {
                             const audio = currentAudioElement; if (!audio) return reject("Audio null");
                             const onEnd = () => { if(currentAudioElement === audio){debugLog("Google TTS finished.");currentAudioElement=null;URL.revokeObjectURL(audioUrl);resolve();} else reject("Stopped externally"); };
                             const onError = (e)=>{ if(currentAudioElement === audio){debugLog(`Google TTS Playback Err: ${e}`);currentAudioElement=null;URL.revokeObjectURL(audioUrl);reject(e);} else reject("Stopped externally"); };
                             audio.addEventListener('ended', onEnd, {once:true}); audio.addEventListener('error', onError, {once:true});
                             if (!isSpeaking) { URL.revokeObjectURL(audioUrl); currentAudioElement = null; return reject("Cancelled"); }
                             audio.play().catch(err => { if(currentAudioElement === audio){debugLog(`Play start err: ${err}`);currentAudioElement = null;URL.revokeObjectURL(audioUrl);reject(err);} });
                         }); return Promise.resolve(); // Success with Google
                    } else { throw new Error("Google TTS API response missing audioContent."); }
                } catch (error) { debugLog(`Google TTS Error: ${error}. Falling back.`); currentAudioElement = null; if (!isSpeaking) return Promise.reject("Cancelled"); /* Fallback below */ }
            } else { debugLog("Google TTS selected but Key or Voice missing. Falling back."); /* Fallback below */ }
        }
        else if (currentTtsProvider === 'elevenlabs') {
            const elevenLabsKey = elevenLabsKeyInput.value.trim();
            const elevenLabsVoice = elevenLabsVoiceInput.value.trim() || "TxGEqnHWrfWFTfGW9XjX";
            if (elevenLabsKey) {
                currentTTSModel = "ElevenLabs TTS"; updateModelInfo();
                debugLog(`Attempting speech with ElevenLabs (Voice: ${elevenLabsVoice}).`);
                try { // Try ElevenLabs
                    const response = await fetch(`https://api.elevenlabs.io/v1/text-to-speech/${elevenLabsVoice}`, { method: "POST", headers: { "Accept": "audio/mpeg", "xi-api-key": elevenLabsKey, "Content-Type": "application/json" }, body: JSON.stringify({ text: text, model_id: "eleven_multilingual_v2", voice_settings: { stability: 0.6, similarity_boost: 0.8 } }) });
                    if (!response.ok) { let eD=null; try{eD=await response.json();}catch(e){} throw new Error(`ElevenLabs API Error: ${eD?.detail?.message || response.status}`); }
                    const audioBlob = await response.blob(); const audioUrl = URL.createObjectURL(audioBlob);
                    if (!isSpeaking) { URL.revokeObjectURL(audioUrl); return Promise.reject("Cancelled"); }
                    currentAudioElement = new Audio(audioUrl); debugLog("ElevenLabs playing...");
                    await new Promise((resolve, reject) => { /* ... (promise logic as before) ... */
                         const audio = currentAudioElement; if (!audio) return reject("Audio null");
                         const onEnd = () => { if (currentAudioElement === audio) { debugLog("ElevenLabs ended."); currentAudioElement = null; URL.revokeObjectURL(audioUrl); resolve(); } else reject("Stopped externally");};
                         const onError = (e) => { if (currentAudioElement === audio) { debugLog(`ElevenLabs Error: ${e}`); currentAudioElement = null; URL.revokeObjectURL(audioUrl); reject(e); } else reject("Stopped externally");};
                         audio.addEventListener('ended', onEnd, { once: true }); audio.addEventListener('error', onError, { once: true });
                         if (!isSpeaking) { URL.revokeObjectURL(audioUrl); currentAudioElement = null; return reject("Cancelled"); }
                         audio.play().catch(err => { if (currentAudioElement === audio) { debugLog(`Play start err: ${err}`); currentAudioElement = null; URL.revokeObjectURL(audioUrl); reject(err); }});
                     }); return Promise.resolve(); // Success with ElevenLabs
                } catch (error) { debugLog(`ElevenLabs TTS Error: ${error}. Falling back.`); currentAudioElement = null; if (!isSpeaking) return Promise.reject("Cancelled"); /* Fallback below */ }
            } else { debugLog("ElevenLabs selected but Key missing. Falling back."); /* Fallback below */ }
        }

        // Fallback to Browser TTS (if provider is 'browser' or other providers failed/misconfigured)
        try { await fallbackTTS(text, targetLang); return Promise.resolve(); }
        catch (error) { debugLog(`Browser TTS Error: ${error}`); return Promise.reject(error === "Cancelled" ? "Cancelled" : error); }
    }

    function fallbackTTS(text, lang) { /* ... (Fallback logic as before) ... */
        return new Promise(async (resolve, reject) => {
            if (!isSpeaking) { debugLog("fallbackTTS cancelled."); return reject("Cancelled"); }
            currentTTSModel = "Browser TTS"; updateModelInfo(); debugLog(`Using Browser TTS (Lang: ${lang}).`);
            const utterance = new SpeechSynthesisUtterance(text); const langCode = lang || currentLanguage; const browserTag = googleLangCodeMap[langCode] || 'en-US'; utterance.lang = browserTag; // Use Google codes map for consistency
            let voices = window.speechSynthesis.getVoices(); if (voices.length === 0) { await new Promise(res => window.speechSynthesis.onvoiceschanged = res); voices = window.speechSynthesis.getVoices(); }
            let voice = voices.find(v => v.lang === browserTag) || voices.find(v => v.lang.startsWith(langCode)); if (voice) { utterance.voice = voice; debugLog(`Voice found: ${voice.name}`); } else { debugLog(`No voice for ${browserTag}.`); }
            utterance.onend = () => { debugLog("Browser TTS finished."); resolve(); }; utterance.onerror = (e) => { debugLog(`Browser TTS Error: ${e.error}`); reject(e.error); };
            if (!isSpeaking) { debugLog("Browser TTS cancelled before speak."); return reject("Cancelled"); } window.speechSynthesis.speak(utterance);
        });
    }

    // --- API Call Functions ---
    async function sendAudioToTranscribe(audioBlob, fileName) {
        if (!apiKey) {
            throw new Error("API Key missing. Consider enabling browser speech recognition.");
        }
        
        // Since Open Router doesn't support audio transcription, we'll need to use browser STT
        // This function remains for backward compatibility but isn't actually used
        debugLog("Warning: Open Router doesn't support audio transcription. Use browser STT instead.");
        throw new Error("Audio transcription not supported with Open Router. Please enable browser speech recognition.");
    }
    async function fetchBotStart() { /* ... (Start logic as before, using languageNameMap) ... */
        let p = initialPromptInput.value; const lN = languageNameMap[currentLanguage] || 'English'; p += `\nGenerate the response in ${lN}.`; const t = themeSelect.value; if (t && t !== "standard" && t !== 'german-a2') p += `\nConsider the theme: ${t}.`; debugLog("fetchBotStart Prompt:\n" + p); lastStartRequest = p; lastStartResponse = "";
        try { 
            const r = await fetch("https://openrouter.ai/api/v1/chat/completions", { 
                method: "POST", 
                headers: { 
                    "Content-Type": "application/json", 
                    "Authorization": "Bearer " + apiKey,
                    "HTTP-Referer": window.location.href,
                    "X-Title": "Story Generation App"
                }, 
                body: JSON.stringify({ 
                    model: currentLLMModel, 
                    messages: [{ role: "user", content: p }], 
                    max_tokens: 400, 
                    temperature: 0.8, 
                    response_format: { type: "json_object" } 
                }) 
            }); 
            const d = await r.json(); 
            debugLog("fetchBotStart Raw: " + JSON.stringify(d)); 
            if (!r.ok) throw new Error(`API Err: ${d?.error?.message || r.status}`); 
            lastStartResponse = d.choices?.[0]?.message?.content || ""; 
            const parsed = safeParseJSON(lastStartResponse); 
            if (parsed?.startSentence && parsed?.hint) { 
                debugLog("fetchBotStart OK."); 
                updateHelpInfosContent(); 
                return parsed; 
            } else { 
                throw new Error("JSON Parse/Keys err."); 
            } 
        } catch (err) { 
            debugLog(`fetchBotStart Err: ${err}`); 
            lastStartResponse = `${err}`; 
            updateHelpInfosContent(); 
            return null; 
        }
    }
    async function fetchBotReaction(storySoFar, userInput) { /* ... (Reaction logic updated for themes as before) ... */
        let baseP = reactionPromptInput.value.replace("{story}", storySoFar || "[No story]").replace("{lastUser}", userInput || "[No input]"); let finalP = baseP; const theme = themeSelect.value; const commentLang = languageNameMap[currentLanguage] || 'English'; let storyHintLangDesc = commentLang; let themeInstructions = "";
        if (theme === 'german-a2') { storyHintLangDesc = "simple German (A2 level)"; finalP += `\nGenerate \`integratedStory\` and \`hint\` in **${storyHintLangDesc}**.`; finalP += `\nGenerate \`comment\` in **${commentLang}**.`; themeInstructions = germanA2Prompt.value.replace("{lastUser}", userInput || "[No input]").replace(/{commentLang}/g, commentLang); debugLog(`Using A2 prompt (Story: ${storyHintLangDesc}, Comment: ${commentLang}).`); }
        else { finalP += `\nGenerate response (story, comment, hint) in **${commentLang}**.`; switch(theme) { case 'lifecoach': themeInstructions = lifecoachPrompt.value.replace(/{commentLang}/g, commentLang); break; case 'creative-writing': themeInstructions = creativewritingPrompt.value.replace(/{commentLang}/g, commentLang); break; case 'mindfulness': themeInstructions = mindfulnessPrompt.value.replace(/{commentLang}/g, commentLang); break; case 'historical-whatif': themeInstructions = historicalwhatifPrompt.value.replace(/{commentLang}/g, commentLang); break; } if (themeInstructions) { debugLog(`Using theme prompt: ${theme}`); } else if (theme && theme !== "standard") { finalP += `\nConsider theme: ${theme}.`; } }
        if(themeInstructions) finalP += "\n" + themeInstructions;
        debugLog("fetchBotReaction Prompt:\n" + finalP); lastReactionRequest = finalP; lastReactionResponse = "";
        try { 
            const r = await fetch("https://openrouter.ai/api/v1/chat/completions", { 
                method: "POST", 
                headers: { 
                    "Content-Type": "application/json", 
                    "Authorization": "Bearer " + apiKey,
                    "HTTP-Referer": window.location.href,
                    "X-Title": "Story Generation App"
                }, 
                body: JSON.stringify({ 
                    model: currentLLMModel, 
                    messages: [{ role: "user", content: finalP }], 
                    max_tokens: 1500, 
                    temperature: 0.9, 
                    response_format: { type: "json_object" } 
                }) 
            }); 
            const d = await r.json(); 
            debugLog("fetchBotReaction Raw: " + JSON.stringify(d)); 
            if (!r.ok) { 
                const msg = d?.error?.message||r.status; 
                if (msg.includes("context_length")) alert("Story too long."); 
                throw new Error(`API Err: ${msg}`); 
            } 
            const finish = d.choices?.[0]?.finish_reason; 
            lastReactionResponse = d.choices?.[0]?.message?.content || ""; 
            if (finish === "length") { 
                debugLog("WARN: Finish 'length'."); 
                lastReactionResponse += "\n[TRUNCATED!]"; 
            } 
            if (lastReactionResponse) { 
                const p = safeParseJSON(lastReactionResponse); 
                if (p?.integratedStory && p?.comment && p?.hint) { 
                    debugLog("fetchBotReaction OK."); 
                    updateHelpInfosContent(); 
                    return p; 
                } else { 
                    throw new Error("JSON Parse/Keys err."); 
                } 
            } else { 
                throw new Error("Empty response."); 
            }
        } catch (err) { debugLog(`fetchBotReaction Err: ${err}`); lastReactionResponse = `${err}`; updateHelpInfosContent(); return null; }
    }
    async function processUserInput(transcript) { /* ... (Process user input logic as before, catching "Cancelled") ... */
       if (!gameActive) { debugLog("processUserInput skipped: inactive."); return; }
       try {
           const botData = await fetchBotReaction(fullStory, transcript); // API call
           if (botData) {
               fullStory = botData.integratedStory; currentHint = botData.hint; lastComment = botData.comment;
               storyTextDiv.textContent = fullStory; ironicTextDiv.textContent = lastComment; hintTextDiv.textContent = currentHint;
               updateHelpInfosContent(); debugLog("Bot reaction processed.");
               setSpeakingStatus(true);
               try { // Wrap speaking sequence
                   const storyLang = (themeSelect.value === 'german-a2') ? 'de' : currentLanguage;
                   await speakText(lastComment, currentLanguage); // Comment in UI lang
                   if(isSpeaking) await new Promise(r => setTimeout(r, 300));
                   if(isSpeaking) await speakText(fullStory, storyLang); // Story/Hint in specific lang
                   if(isSpeaking) await new Promise(r => setTimeout(r, 300));
                   if(isSpeaking) await speakText(currentHint, storyLang);
               } catch(ttsError) { // Catch errors *or* cancellation
                   if(ttsError !== "Cancelled") { debugLog(`TTS sequence error: ${ttsError}`); alert("Speech error."); }
                   else { debugLog("TTS sequence cancelled by user."); }
               } finally { setSpeakingStatus(false); } // Always reset speaking status
               debugLog("User input processing & TTS sequence finished.");
           } else { ironicTextDiv.textContent = "Error processing response."; hintTextDiv.textContent = ""; debugLog("Processing failed: botData null."); }
       } catch(error) { debugLog(`processUserInput Err: ${error}`); alert("Error processing input."); ironicTextDiv.textContent = "Error."; hintTextDiv.textContent = ""; setSpeakingStatus(false); }
     }

    // --- UI Helper Functions ---
    function updateContribsModal() { /* ... (Modal update logic as before) ... */
         contribList.innerHTML = ""; if (userContributions.length === 0) { contribList.innerHTML = `<li>${getTranslation('noContributions')}</li>`; } else { userContributions.forEach((c, i) => { const li = document.createElement("li"); li.textContent = `${i + 1}. ${c}`; contribList.appendChild(li); }); }
    }

    // Function to update all UI text based on the selected language
    function updateUILanguage() {
        // Update all text elements with translations
        document.getElementById("appTitle").textContent = getTranslation("appTitle");
        document.getElementById("startGameBtn").textContent = getTranslation("startGame");
        document.getElementById("restartGameBtn").textContent = getTranslation("restartGame");
        document.getElementById("stopGameBtn").textContent = getTranslation("stopGame");
        document.getElementById("settingsBtn").textContent = getTranslation("settings");
        document.getElementById("showContribsBtn").textContent = getTranslation("showContribs");
        document.getElementById("stopTTSBtn").textContent = getTranslation("stopSpeaking");
        document.getElementById("processingText").textContent = getTranslation("processing");
        document.getElementById("lastUserInputTitle").textContent = getTranslation("lastUserInput");
        document.getElementById("commentFeedbackTitle").textContent = getTranslation("commentFeedback");
        document.getElementById("currentStoryTitle").textContent = getTranslation("currentStory");
        document.getElementById("hintTitle").textContent = getTranslation("hint");
        document.getElementById("startRecordBtn").textContent = getTranslation("startRecording");
        document.getElementById("stopRecordBtn").textContent = getTranslation("stopRecording");
        
        // Settings modal
        document.getElementById("settingsTitle").textContent = getTranslation("settings");
        document.getElementById("openRouterNote").textContent = getTranslation("openRouterNote");
        document.getElementById("apiKeyLabel").textContent = getTranslation("apiKeyLabel");
        document.getElementById("apiKey").placeholder = getTranslation("apiKeyPlaceholder");
        document.getElementById("modelSelectLabel").textContent = getTranslation("modelSelectLabel");
        document.getElementById("interfaceLanguageLabel").textContent = getTranslation("interfaceLanguage");
        document.getElementById("ttsSettingsTitle").textContent = getTranslation("ttsSettings");
        document.getElementById("ttsProviderLabel").textContent = getTranslation("ttsProvider");
        document.getElementById("storyGenSettingsTitle").textContent = getTranslation("storyGenSettings");
        document.getElementById("initialPromptLabel").textContent = getTranslation("initialPrompt");
        document.getElementById("reactionPromptLabel").textContent = getTranslation("reactionPrompt");
        document.getElementById("themeLabel").textContent = getTranslation("themeLabel");
        document.getElementById("otherSettingsTitle").textContent = getTranslation("otherSettings");
        document.getElementById("autoStartTimeLabel").textContent = getTranslation("autoStartTime");
        document.getElementById("useBrowserSttText").textContent = getTranslation("useBrowserStt");
        document.getElementById("showDebugInfoText").textContent = getTranslation("showDebugInfo");
        document.getElementById("debugLogTitle").textContent = getTranslation("debugLog");
        document.getElementById("copyDebugBtn").textContent = getTranslation("copyDebug");
        document.getElementById("clearDebugBtn").textContent = getTranslation("clearDebug");
        
        // Contributions modal
        document.getElementById("allContributionsTitle").textContent = getTranslation("allContributions");
        
        // Update content that depends on game state
        updateUIState();
    }
    
    // --- Auto-Start ---
    setInterval(() => { /* ... (Auto-start logic as before) ... */
        const now = new Date(); const [h, m] = autoStartTimeInput.value.split(":").map(Number); if (!isNaN(h) && !isNaN(m) && now.getHours()===h && now.getMinutes()===m && !gameActive && !isProcessing && !isSpeaking) { debugLog(`Auto-Start Time (${autoStartTimeInput.value}) reached.`); startGame(); }
    }, 60000);

  </script>
</body>
</html>
